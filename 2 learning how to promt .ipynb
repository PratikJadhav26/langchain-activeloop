{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af66b58b",
   "metadata": {},
   "source": [
    "### Intro to Prompt Engineering: Tips and Tricks3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feacfb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme: interstellar travel\n",
      "Year: 3030\n",
      "AI-generated song title: \n",
      "\"Journey to the Stars: 3030\"\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "# Initialize LLM\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "template = \"\"\"\n",
    "As a futuristic robot band conductor, I need you to help me come up with a song title.\n",
    "What's a cool song title for a song about {theme} in the year {year}?\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"theme\", \"year\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "# Create the LLMChain for the prompt\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "# Input data for the prompt\n",
    "input_data = {\"theme\": \"interstellar travel\", \"year\": \"3030\"}\n",
    "\n",
    "# Create LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the LLMChain to get the AI-generated song title\n",
    "response = chain.run(input_data)\n",
    "\n",
    "print(\"Theme: interstellar travel\")\n",
    "print(\"Year: 3030\")\n",
    "print(\"AI-generated song title:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b88481",
   "metadata": {},
   "source": [
    "## Few Shot Prompting\n",
    "Few Shot Prompting In the next example, the LLM is asked to provide the emotion associated with a given color based on a few examples of color-emotion pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ffcce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color: white\n",
      "Emotion:  creativity\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "examples = [\n",
    "    {\"color\": \"red\", \"emotion\": \"passion\"},\n",
    "    {\"color\": \"blue\", \"emotion\": \"serenity\"},\n",
    "    {\"color\": \"green\", \"emotion\": \"tranquility\"},\n",
    "]\n",
    "\n",
    "example_formatter_template = \"\"\"\n",
    "Color: {color}\n",
    "Emotion: {emotion}\\n\n",
    "\"\"\"\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"color\", \"emotion\"],\n",
    "    template=example_formatter_template,\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Here are some examples of colors and the emotions associated with them:\\n\\n\",\n",
    "    suffix=\"\\n\\nNow, given a new color, identify the emotion associated with it:\\n\\nColor: {input}\\nEmotion:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\",\n",
    ")\n",
    "\n",
    "formatted_prompt = few_shot_prompt.format(input=\"purple\")\n",
    "\n",
    "# Create the LLMChain for the prompt\n",
    "chain = LLMChain(llm=llm, prompt=PromptTemplate(template=formatted_prompt, input_variables=[]))\n",
    "\n",
    "# Run the LLMChain to get the AI-generated emotion associated with the input color\n",
    "response = chain.run({})\n",
    "\n",
    "print(\"Color: white\")\n",
    "print(\"Emotion:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22694e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist: Sir Isaac Newton\n",
      "Fact: \n",
      "Sir Isaac Newton's theory of gravity states that every object in the universe attracts every other object with a force that is directly proportional to the product of their masses and inversely proportional to the square of the distance between them. This force is known as the gravitational force.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "# Prompt 1\n",
    "template_question = \"\"\"What is the name of the famous scientist who developed the theory of gravity?\n",
    "Answer: \"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# Prompt 2\n",
    "template_fact = \"\"\"Provide a brief description of {scientist}'s theory of gravity\n",
    "Answer: \"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Extract the scientist's name from the response\n",
    "scientist = response_question.strip()\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"scientist\": scientist}\n",
    "\n",
    "# Run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Scientist:\", scientist)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df35fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04372f87",
   "metadata": {},
   "source": [
    "### A well-structured prompt example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87659f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: What are some tips for improving communication skills?\n",
      "AI Response:  Practice active listening, be mindful of your body language, and be open to constructive feedback.\n"
     ]
    }
   ],
   "source": [
    "from langchain import FewShotPromptTemplate, PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What's the secret to happiness?\",\n",
    "        \"answer\": \"Finding balance in life and learning to enjoy the small moments.\"\n",
    "    }, {\n",
    "        \"query\": \"How can I become more productive?\",\n",
    "        \"answer\": \"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
    "life coach. The assistant provides insightful and practical advice to the users' questions. Here are some\n",
    "examples: \n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Create the LLMChain for the few-shot prompt template\n",
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt_template)\n",
    "\n",
    "# Define the user query\n",
    "user_query = \"What are some tips for improving communication skills?\"\n",
    "\n",
    "# Run the LLMChain for the user query\n",
    "response = chain.run({\"query\": user_query})\n",
    "\n",
    "print(\"User Query:\", user_query)\n",
    "print(\"AI Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e973f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e06afd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tropical forests and mangrove swamps\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain, FewShotPromptTemplate,PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "examples = [\n",
    "    {\"animal\": \"lion\", \"habitat\": \"savanna\"},\n",
    "    {\"animal\": \"polar bear\", \"habitat\": \"Arctic ice\"},\n",
    "    {\"animal\": \"elephant\", \"habitat\": \"African grasslands\"}\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "Animal: {animal}\n",
    "Habitat: {habitat}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"animal\", \"habitat\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Identify the habitat of the given animal\",\n",
    "    suffix=\"Animal: {input}\\nHabitat:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\\n\",\n",
    ")\n",
    "\n",
    "# Create the LLMChain for the dynamic_prompt\n",
    "chain = LLMChain(llm=llm, prompt=dynamic_prompt)\n",
    "\n",
    "# Run the LLMChain with input_data\n",
    "input_data = {\"input\": \"tiger\"}\n",
    "response = chain.run(input_data)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df633400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt_template.save(\"awesome_prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12953030",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (3440900330.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [17]\u001b[1;36m\u001b[0m\n\u001b[1;33m    loaded_prompt = load_prompt(\"awesome_prompt.json\"\u001b[0m\n\u001b[1;37m                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "loaded_prompt = load_prompt(\"awesome_prompt.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989b0e54",
   "metadata": {},
   "source": [
    "### Few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ff18b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I be lovin' the art of code plunderin'.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "template=\"You are a helpful assistant that translates english to pirate.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "example_human = HumanMessagePromptTemplate.from_template(\"Hi\")\n",
    "example_ai = AIMessagePromptTemplate.from_template(\"Argh me mateys\")\n",
    "human_template=\"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, example_human, example_ai, human_message_prompt])\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "chain.run(\"I love programming.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c84a432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "# create our examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What's the weather like?\",\n",
    "        \"answer\": \"It's raining cats and dogs, better bring an umbrella!\"\n",
    "    }, {\n",
    "        \"query\": \"How old are you?\",\n",
    "        \"answer\": \"Age is just a number, but I'm timeless.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# create an example template\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# create a prompt example from above template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
    "assistant. The assistant is known for its humor and wit, providing\n",
    "entertaining and amusing responses to users' questions. Here are some\n",
    "examples:\n",
    "\"\"\"\n",
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "# now create the few-shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b872d2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The secret to happiness is a good sense of humor and a never-ending supply of chocolate.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=chat, prompt=few_shot_prompt_template)\n",
    "chain.run(\"What's the secret to happiness?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27be378a",
   "metadata": {},
   "source": [
    "#### Example selectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c2cbbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44b24e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "    {\"word\": \"energetic\", \"antonym\": \"lethargic\"},\n",
    "    {\"word\": \"sunny\", \"antonym\": \"gloomy\"},\n",
    "    {\"word\": \"windy\", \"antonym\": \"calm\"},\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "Word: {word}\n",
    "Antonym: {antonym}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffd93aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "676e6c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Word: {input}\\nAntonym:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "badc5182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "\n",
      "\n",
      "Word: tall\n",
      "Antonym: short\n",
      "\n",
      "\n",
      "\n",
      "Word: energetic\n",
      "Antonym: lethargic\n",
      "\n",
      "\n",
      "\n",
      "Word: sunny\n",
      "Antonym: gloomy\n",
      "\n",
      "\n",
      "Word: big\n",
      "Antonym:\n"
     ]
    }
   ],
   "source": [
    "print(dynamic_prompt.format(input=\"big\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f12b5b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: deepLake in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (3.8.11)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from deepLake) (4.64.0)\n",
      "Requirement already satisfied: lz4 in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from deepLake) (4.3.2)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from deepLake) (8.0.4)\n",
      "Requirement already satisfied: humbug>=0.3.1 in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from deepLake) (0.3.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from deepLake) (1.21.5)\n",
      "Requirement already satisfied: pydantic in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from deepLake) (1.10.13)\n",
      "Requirement already satisfied: pathos in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from deepLake) (0.3.1)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from deepLake) (9.0.1)\n",
      "Requirement already satisfied: boto3 in c:\\programdata\\anaconda3\\lib\\site-packages (from deepLake) (1.21.32)\n",
      "Requirement already satisfied: pyjwt in c:\\programdata\\anaconda3\\lib\\site-packages (from deepLake) (2.1.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from humbug>=0.3.1->deepLake) (2.27.1)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.32 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->deepLake) (1.24.32)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->deepLake) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->deepLake) (0.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.25.0,>=1.24.32->boto3->deepLake) (1.26.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.25.0,>=1.24.32->boto3->deepLake) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.32->boto3->deepLake) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->deepLake) (0.4.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from pathos->deepLake) (0.70.15)\n",
      "Requirement already satisfied: pox>=0.3.3 in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from pathos->deepLake) (0.3.3)\n",
      "Requirement already satisfied: dill>=0.3.7 in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from pathos->deepLake) (0.3.7)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from pathos->deepLake) (1.7.6.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from pydantic->deepLake) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->humbug>=0.3.1->deepLake) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->humbug>=0.3.1->deepLake) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from requests->humbug>=0.3.1->deepLake) (2.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deepLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3e39041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50cee28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eyJhbGciOiJIUzUxMiIsImlhdCI6MTcwMjYxNzI4MiwiZXhwIjoxNzM0MjM5NjY1fQ.eyJpZCI6InByYXRpa2phZGhhdjk3MjYifQ.kOptiDnD4utMKgZ1sPgwhgCPpGtyOMI13JA-esrLyjDe2ODijqrudAT6GOKpbqGrGg56sQ3Xu9_fRC3jGIwkZQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5d22335",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not import deeplake python package. Please install it with `pip install deeplake`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m my_activeloop_dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain_course_fewshot_selector\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     25\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhub://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmy_activeloop_org_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmy_activeloop_dataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 26\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mDeepLake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Embedding function\u001b[39;00m\n\u001b[0;32m     29\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain\\vectorstores\\deeplake.py:123\u001b[0m, in \u001b[0;36mDeepLake.__init__\u001b[1;34m(self, dataset_path, token, embedding_function, read_only, ingestion_batch_size, num_workers, verbose, exec_option, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m verbose\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _DEEPLAKE_INSTALLED \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import deeplake python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install deeplake`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    126\u001b[0m     )\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version_compare(deeplake\u001b[38;5;241m.\u001b[39m__version__, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.6.2\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeeplake version should be >= 3.6.3, but you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mve installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeeplake\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider upgrading deeplake version \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124m            pip install --upgrade deeplake.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    133\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Could not import deeplake python package. Please install it with `pip install deeplake`."
     ]
    }
   ],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "# Create a PromptTemplate\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "\n",
    "# Define some examples\n",
    "examples = [\n",
    "    {\"input\": \"0°C\", \"output\": \"32°F\"},\n",
    "    {\"input\": \"10°C\", \"output\": \"50°F\"},\n",
    "    {\"input\": \"20°C\", \"output\": \"68°F\"},\n",
    "    {\"input\": \"30°C\", \"output\": \"86°F\"},\n",
    "    {\"input\": \"40°C\", \"output\": \"104°F\"},\n",
    "]\n",
    "\n",
    "# create Deep Lake dataset\n",
    "# TODO: use your organization id here.  (by default, org id is your username)\n",
    "my_activeloop_org_id = \"<YOUR-ACTIVELOOP-ORG-ID>\" \n",
    "my_activeloop_dataset_name = \"langchain_course_fewshot_selector\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path)\n",
    "\n",
    "# Embedding function\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Instantiate SemanticSimilarityExampleSelector using the examples\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples, embeddings, db, k=1\n",
    ")\n",
    "\n",
    "# Create a FewShotPromptTemplate using the example_selector\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Convert the temperature from Celsius to Fahrenheit\",\n",
    "    suffix=\"Input: {temperature}\\nOutput:\", \n",
    "    input_variables=[\"temperature\"],\n",
    ")\n",
    "\n",
    "# Test the similar_prompt with different inputs\n",
    "print(similar_prompt.format(temperature=\"10°C\"))   # Test with an input\n",
    "print(similar_prompt.format(temperature=\"30°C\"))  # Test with another input\n",
    "\n",
    "# Add a new example to the SemanticSimilarityExampleSelector\n",
    "similar_prompt.example_selector.add_example({\"input\": \"50°C\", \"output\": \"122°F\"})\n",
    "print(similar_prompt.format(temperature=\"40°C\")) # Test with a new input after adding the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c69c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Suggestions(BaseModel):\n",
    "    words: List[str] = Field(description=\"list of substitue words based on context\")\n",
    "\n",
    "    # Throw error in case of receiving a numbered-list from API\n",
    "    @validator('words')\n",
    "    def not_start_with_number(cls, field):\n",
    "        for item in field:\n",
    "            if item[0].isnumeric():\n",
    "                raise ValueError(\"The word can not start with numbers!\")\n",
    "        return field\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7d788df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Offer a list of suggestions to substitue the specified target_word based the presented context.\n",
    "{format_instructions}\n",
    "target_word={target_word}\n",
    "context={context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"target_word\", \"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "model_input = prompt.format_prompt(\n",
    "\t\t\ttarget_word=\"behaviour\",\n",
    "\t\t\tcontext=\"The behaviour of the students in the classroom was disruptive and made it difficult for the teacher to conduct the lesson.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2d25c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suggestions(words=['conduct', 'manner', 'action', 'demeanor', 'comportment'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OpenAI(model_name='text-davinci-003', temperature=0.0)\n",
    "\n",
    "output = model(model_input.to_string())\n",
    "\n",
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e41f282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30c0ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Offer a list of suggestions to substitute the specified target_word based on the presented context and the reasoning for each word.\n",
    "{format_instructions}\n",
    "target_word={target_word}\n",
    "context={context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4b8c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Suggestions(BaseModel):\n",
    "    words: List[str] = Field(description=\"list of substitue words based on context\")\n",
    "    reasons: List[str] = Field(description=\"the reasoning of why this word fits the context\")\n",
    "    \n",
    "    @validator('words')\n",
    "    def not_start_with_number(cls, field):\n",
    "      for item in field:\n",
    "        if item[0].isnumeric():\n",
    "          raise ValueError(\"The word can not start with numbers!\")\n",
    "      return field\n",
    "    \n",
    "    @validator('reasons')\n",
    "    def end_with_dot(cls, field):\n",
    "      for idx, item in enumerate( field ):\n",
    "        if item[-1] != \".\":\n",
    "          field[idx] += \".\"\n",
    "      return field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e05fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e2b6f019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conduct',\n",
       " 'Actions',\n",
       " 'Demeanor',\n",
       " 'Mannerisms',\n",
       " 'Attitude',\n",
       " 'Performance',\n",
       " 'Reactions',\n",
       " 'Interactions',\n",
       " 'Habits',\n",
       " 'Repertoire',\n",
       " 'Responses',\n",
       " 'Interplay',\n",
       " 'Interaction',\n",
       " 'Activity',\n",
       " 'Posture',\n",
       " 'Deportment',\n",
       " 'Bearing',\n",
       " 'Disposition.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Prepare the Prompt\n",
    "template = \"\"\"\n",
    "Offer a list of suggestions to substitute the word '{target_word}' based the presented the following text: {context}.\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"target_word\", \"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "model_input = prompt.format(\n",
    "  target_word=\"behaviour\",\n",
    "  context=\"The behaviour of the students in the classroom was disruptive and made it difficult for the teacher to conduct the lesson.\"\n",
    ")\n",
    "\n",
    "# Loading OpenAI API\n",
    "model = OpenAI(model_name='text-davinci-003', temperature=0.0)\n",
    "\n",
    "# Send the Request\n",
    "output = model(model_input)\n",
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a9b09228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import DeepLake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cbe45a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# text to write to a local file\n",
    "# taken from https://www.theverge.com/2023/3/14/23639313/google-ai-language-model-palm-api-challenge-openai\n",
    "text = \"\"\"Google opens up its AI language model PaLM to challenge OpenAI and GPT-3\n",
    "Google is offering developers access to one of its most advanced AI language models: PaLM.\n",
    "The search giant is launching an API for PaLM alongside a number of AI enterprise tools\n",
    "it says will help businesses “generate text, images, code, videos, audio, and more from\n",
    "simple natural language prompts.”\n",
    "\n",
    "PaLM is a large language model, or LLM, similar to the GPT series created by OpenAI or\n",
    "Meta’s LLaMA family of models. Google first announced PaLM in April 2022. Like other LLMs,\n",
    "PaLM is a flexible system that can potentially carry out all sorts of text generation and\n",
    "editing tasks. You could train PaLM to be a conversational chatbot like ChatGPT, for\n",
    "example, or you could use it for tasks like summarizing text or even writing code.\n",
    "(It’s similar to features Google also announced today for its Workspace apps like Google\n",
    "Docs and Gmail.)\n",
    "\"\"\"\n",
    "\n",
    "# write text to local file\n",
    "with open(\"my_file.txt\", \"w\") as file:\n",
    "    file.write(text)\n",
    "\n",
    "# use TextLoader to load text from local file\n",
    "loader = TextLoader(\"my_file.txt\")\n",
    "docs_from_file = loader.load()\n",
    "\n",
    "print(len(docs_from_file))\n",
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a9960c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 373, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Google opens up its AI language model PaLM to challenge OpenAI and GPT-3\\nGoogle is offering developers access to one of its most advanced AI language models: PaLM.\\nThe search giant is launching an API for PaLM alongside a number of AI enterprise tools\\nit says will help businesses “generate text, images, code, videos, audio, and more from\\nsimple natural language prompts.”', metadata={'source': 'my_file.txt'}), Document(page_content='PaLM is a large language model, or LLM, similar to the GPT series created by OpenAI or\\nMeta’s LLaMA family of models. Google first announced PaLM in April 2022. Like other LLMs,\\nPaLM is a flexible system that can potentially carry out all sorts of text generation and\\nediting tasks. You could train PaLM to be a conversational chatbot like ChatGPT, for\\nexample, or you could use it for tasks like summarizing text or even writing code.\\n(It’s similar to features Google also announced today for its Workspace apps like Google\\nDocs and Gmail.)', metadata={'source': 'my_file.txt'})]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# create a text splitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "\n",
    "# split documents into chunks\n",
    "docs = text_splitter.split_documents(docs_from_file)\n",
    "print(docs)\n",
    "\n",
    "print(len(docs))\n",
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4e80c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "be23d630",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not import deeplake python package. Please install it with `pip install deeplake`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [80]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m my_activeloop_dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain_course_indexers_retrievers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhub://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmy_activeloop_org_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmy_activeloop_dataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mDeepLake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# add documents to our Deep Lake dataset\u001b[39;00m\n\u001b[0;32m      7\u001b[0m db\u001b[38;5;241m.\u001b[39madd_documents(docs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain\\vectorstores\\deeplake.py:123\u001b[0m, in \u001b[0;36mDeepLake.__init__\u001b[1;34m(self, dataset_path, token, embedding_function, read_only, ingestion_batch_size, num_workers, verbose, exec_option, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m verbose\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _DEEPLAKE_INSTALLED \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import deeplake python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install deeplake`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    126\u001b[0m     )\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version_compare(deeplake\u001b[38;5;241m.\u001b[39m__version__, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.6.2\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeeplake version should be >= 3.6.3, but you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mve installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeeplake\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider upgrading deeplake version \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124m            pip install --upgrade deeplake.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    133\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Could not import deeplake python package. Please install it with `pip install deeplake`."
     ]
    }
   ],
   "source": [
    "my_activeloop_org_id = \"<pratikjadhav9726>\"\n",
    "my_activeloop_dataset_name = \"langchain_course_indexers_retrievers\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec9473f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47c6eb6e",
   "metadata": {},
   "source": [
    "### Streamlined Data Ingestion: Text, PyPDF,  Selenium URL Loaders, and Google Drive Sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "52681407",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Person ID,Gender,Age,Occupation,Sleep Duration,Quality of Sleep,Physical Activity Level,Stress Level,BMI Category,Blood Pressure,Heart Rate,Daily Steps,Sleep Disorder\\n1,Male,27,Software Engineer,6.1,6,42,6,Overweight,126/83,77,4200,None\\n2,Male,28,Doctor,6.2,6,60,8,Normal,125/80,75,10000,None\\n3,Male,28,Doctor,6.2,6,60,8,Normal,125/80,75,10000,None\\n4,Male,28,Sales Representative,5.9,4,30,8,Obese,140/90,85,3000,Sleep Apnea\\n5,Male,28,Sales Representative,5.9,4,30,8,Obese,140/90,85,3000,Sleep Apnea\\n6,Male,28,Software Engineer,5.9,4,30,8,Obese,140/90,85,3000,Insomnia\\n7,Male,29,Teacher,6.3,6,40,7,Obese,140/90,82,3500,Insomnia\\n8,Male,29,Doctor,7.8,7,75,6,Normal,120/80,70,8000,None\\n9,Male,29,Doctor,7.8,7,75,6,Normal,120/80,70,8000,None\\n10,Male,29,Doctor,7.8,7,75,6,Normal,120/80,70,8000,None\\n11,Male,29,Doctor,6.1,6,30,8,Normal,120/80,70,8000,None\\n12,Male,29,Doctor,7.8,7,75,6,Normal,120/80,70,8000,None\\n13,Male,29,Doctor,6.1,6,30,8,Normal,120/80,70,8000,None\\n14,Male,29,Doctor,6,6,30,8,Normal,120/80,70,8000,None\\n15,Male,29,Doctor,6,6,30,8,Normal,120/80,70,8000,None\\n16,Male,29,Doctor,6,6,30,8,Normal,120/80,70,8000,None\\n17,Female,29,Nurse,6.5,5,40,7,Normal Weight,132/87,80,4000,Sleep Apnea\\n18,Male,29,Doctor,6,6,30,8,Normal,120/80,70,8000,Sleep Apnea\\n19,Female,29,Nurse,6.5,5,40,7,Normal Weight,132/87,80,4000,Insomnia\\n20,Male,30,Doctor,7.6,7,75,6,Normal,120/80,70,8000,None\\n21,Male,30,Doctor,7.7,7,75,6,Normal,120/80,70,8000,None\\n22,Male,30,Doctor,7.7,7,75,6,Normal,120/80,70,8000,None\\n23,Male,30,Doctor,7.7,7,75,6,Normal,120/80,70,8000,None\\n24,Male,30,Doctor,7.7,7,75,6,Normal,120/80,70,8000,None\\n25,Male,30,Doctor,7.8,7,75,6,Normal,120/80,70,8000,None\\n26,Male,30,Doctor,7.9,7,75,6,Normal,120/80,70,8000,None\\n27,Male,30,Doctor,7.8,7,75,6,Normal,120/80,70,8000,None\\n28,Male,30,Doctor,7.9,7,75,6,Normal,120/80,70,8000,None\\n29,Male,30,Doctor,7.9,7,75,6,Normal,120/80,70,8000,None\\n30,Male,30,Doctor,7.9,7,75,6,Normal,120/80,70,8000,None\\n31,Female,30,Nurse,6.4,5,35,7,Normal Weight,130/86,78,4100,Sleep Apnea\\n32,Female,30,Nurse,6.4,5,35,7,Normal Weight,130/86,78,4100,Insomnia\\n33,Female,31,Nurse,7.9,8,75,4,Normal Weight,117/76,69,6800,None\\n34,Male,31,Doctor,6.1,6,30,8,Normal,125/80,72,5000,None\\n35,Male,31,Doctor,7.7,7,75,6,Normal,120/80,70,8000,None\\n36,Male,31,Doctor,6.1,6,30,8,Normal,125/80,72,5000,None\\n37,Male,31,Doctor,6.1,6,30,8,Normal,125/80,72,5000,None\\n38,Male,31,Doctor,7.6,7,75,6,Normal,120/80,70,8000,None\\n39,Male,31,Doctor,7.6,7,75,6,Normal,120/80,70,8000,None\\n40,Male,31,Doctor,7.6,7,75,6,Normal,120/80,70,8000,None\\n41,Male,31,Doctor,7.7,7,75,6,Normal,120/80,70,8000,None\\n42,Male,31,Doctor,7.7,7,75,6,Normal,120/80,70,8000,None\\n43,Male,31,Doctor,7.7,7,75,6,Normal,120/80,70,8000,None\\n44,Male,31,Doctor,7.8,7,75,6,Normal,120/80,70,8000,None\\n45,Male,31,Doctor,7.7,7,75,6,Normal,120/80,70,8000,None\\n46,Male,31,Doctor,7.8,7,75,6,Normal,120/80,70,8000,None\\n47,Male,31,Doctor,7.7,7,75,6,Normal,120/80,70,8000,None\\n48,Male,31,Doctor,7.8,7,75,6,Normal,120/80,70,8000,None\\n49,Male,31,Doctor,7.7,7,75,6,Normal,120/80,70,8000,None\\n50,Male,31,Doctor,7.7,7,75,6,Normal,120/80,70,8000,Sleep Apnea\\n51,Male,32,Engineer,7.5,8,45,3,Normal,120/80,70,8000,None\\n52,Male,32,Engineer,7.5,8,45,3,Normal,120/80,70,8000,None\\n53,Male,32,Doctor,6,6,30,8,Normal,125/80,72,5000,None\\n54,Male,32,Doctor,7.6,7,75,6,Normal,120/80,70,8000,None\\n55,Male,32,Doctor,6,6,30,8,Normal,125/80,72,5000,None\\n56,Male,32,Doctor,6,6,30,8,Normal,125/80,72,5000,None\\n57,Male,32,Doctor,7.7,7,75,6,Normal,120/80,70,8000,None\\n58,Male,32,Doctor,6,6,30,8,Normal,125/80,72,5000,None\\n59,Male,32,Doctor,6,6,30,8,Normal,125/80,72,5000,None\\n60,Male,32,Doctor,7.7,7,75,6,Normal,120/80,70,8000,None\\n61,Male,32,Doctor,6,6,30,8,Normal,125/80,72,5000,None\\n62,Male,32,Doctor,6,6,30,8,Normal,125/80,72,5000,None\\n63,Male,32,Doctor,6.2,6,30,8,Normal,125/80,72,5000,None\\n64,Male,32,Doctor,6.2,6,30,8,Normal,125/80,72,5000,None\\n65,Male,32,Doctor,6.2,6,30,8,Normal,125/80,72,5000,None\\n66,Male,32,Doctor,6.2,6,30,8,Normal,125/80,72,5000,None\\n67,Male,32,Accountant,7.2,8,50,6,Normal Weight,118/76,68,7000,None\\n68,Male,33,Doctor,6,6,30,8,Normal,125/80,72,5000,Insomnia\\n69,Female,33,Scientist,6.2,6,50,6,Overweight,128/85,76,5500,None\\n70,Female,33,Scientist,6.2,6,50,6,Overweight,128/85,76,5500,None\\n71,Male,33,Doctor,6.1,6,30,8,Normal,125/80,72,5000,None\\n72,Male,33,Doctor,6.1,6,30,8,Normal,125/80,72,5000,None\\n73,Male,33,Doctor,6.1,6,30,8,Normal,125/80,72,5000,None\\n74,Male,33,Doctor,6.1,6,30,8,Normal,125/80,72,5000,None\\n75,Male,33,Doctor,6,6,30,8,Normal,125/80,72,5000,None\\n76,Male,33,Doctor,6,6,30,8,Normal,125/80,72,5000,None\\n77,Male,33,Doctor,6,6,30,8,Normal,125/80,72,5000,None\\n78,Male,33,Doctor,6,6,30,8,Normal,125/80,72,5000,None\\n79,Male,33,Doctor,6,6,30,8,Normal,125/80,72,5000,None\\n80,Male,33,Doctor,6,6,30,8,Normal,125/80,72,5000,None\\n81,Female,34,Scientist,5.8,4,32,8,Overweight,131/86,81,5200,Sleep Apnea\\n82,Female,34,Scientist,5.8,4,32,8,Overweight,131/86,81,5200,Sleep Apnea\\n83,Male,35,Teacher,6.7,7,40,5,Overweight,128/84,70,5600,None\\n84,Male,35,Teacher,6.7,7,40,5,Overweight,128/84,70,5600,None\\n85,Male,35,Software Engineer,7.5,8,60,5,Normal Weight,120/80,70,8000,None\\n86,Female,35,Accountant,7.2,8,60,4,Normal,115/75,68,7000,None\\n87,Male,35,Engineer,7.2,8,60,4,Normal,125/80,65,5000,None\\n88,Male,35,Engineer,7.2,8,60,4,Normal,125/80,65,5000,None\\n89,Male,35,Engineer,7.3,8,60,4,Normal,125/80,65,5000,None\\n90,Male,35,Engineer,7.3,8,60,4,Normal,125/80,65,5000,None\\n91,Male,35,Engineer,7.3,8,60,4,Normal,125/80,65,5000,None\\n92,Male,35,Engineer,7.3,8,60,4,Normal,125/80,65,5000,None\\n93,Male,35,Software Engineer,7.5,8,60,5,Normal Weight,120/80,70,8000,None\\n94,Male,35,Lawyer,7.4,7,60,5,Obese,135/88,84,3300,Sleep Apnea\\n95,Female,36,Accountant,7.2,8,60,4,Normal,115/75,68,7000,Insomnia\\n96,Female,36,Accountant,7.1,8,60,4,Normal,115/75,68,7000,None\\n97,Female,36,Accountant,7.2,8,60,4,Normal,115/75,68,7000,None\\n98,Female,36,Accountant,7.1,8,60,4,Normal,115/75,68,7000,None\\n99,Female,36,Teacher,7.1,8,60,4,Normal,115/75,68,7000,None\\n100,Female,36,Teacher,7.1,8,60,4,Normal,115/75,68,7000,None\\n101,Female,36,Teacher,7.2,8,60,4,Normal,115/75,68,7000,None\\n102,Female,36,Teacher,7.2,8,60,4,Normal,115/75,68,7000,None\\n103,Female,36,Teacher,7.2,8,60,4,Normal,115/75,68,7000,None\\n104,Male,36,Teacher,6.6,5,35,7,Overweight,129/84,74,4800,Sleep Apnea\\n105,Female,36,Teacher,7.2,8,60,4,Normal,115/75,68,7000,Sleep Apnea\\n106,Male,36,Teacher,6.6,5,35,7,Overweight,129/84,74,4800,Insomnia\\n107,Female,37,Nurse,6.1,6,42,6,Overweight,126/83,77,4200,None\\n108,Male,37,Engineer,7.8,8,70,4,Normal Weight,120/80,68,7000,None\\n109,Male,37,Engineer,7.8,8,70,4,Normal Weight,120/80,68,7000,None\\n110,Male,37,Lawyer,7.4,8,60,5,Normal,130/85,68,8000,None\\n111,Female,37,Accountant,7.2,8,60,4,Normal,115/75,68,7000,None\\n112,Male,37,Lawyer,7.4,8,60,5,Normal,130/85,68,8000,None\\n113,Female,37,Accountant,7.2,8,60,4,Normal,115/75,68,7000,None\\n114,Male,37,Lawyer,7.4,8,60,5,Normal,130/85,68,8000,None\\n115,Female,37,Accountant,7.2,8,60,4,Normal,115/75,68,7000,None\\n116,Female,37,Accountant,7.2,8,60,4,Normal,115/75,68,7000,None\\n117,Female,37,Accountant,7.2,8,60,4,Normal,115/75,68,7000,None\\n118,Female,37,Accountant,7.2,8,60,4,Normal,115/75,68,7000,None\\n119,Female,37,Accountant,7.2,8,60,4,Normal,115/75,68,7000,None\\n120,Female,37,Accountant,7.2,8,60,4,Normal,115/75,68,7000,None\\n121,Female,37,Accountant,7.2,8,60,4,Normal,115/75,68,7000,None\\n122,Female,37,Accountant,7.2,8,60,4,Normal,115/75,68,7000,None\\n123,Female,37,Accountant,7.2,8,60,4,Normal,115/75,68,7000,None\\n124,Female,37,Accountant,7.2,8,60,4,Normal,115/75,68,7000,None\\n125,Female,37,Accountant,7.2,8,60,4,Normal,115/75,68,7000,None\\n126,Female,37,Nurse,7.5,8,60,4,Normal Weight,120/80,70,8000,None\\n127,Male,38,Lawyer,7.3,8,60,5,Normal,130/85,68,8000,None\\n128,Female,38,Accountant,7.1,8,60,4,Normal,115/75,68,7000,None\\n129,Male,38,Lawyer,7.3,8,60,5,Normal,130/85,68,8000,None\\n130,Male,38,Lawyer,7.3,8,60,5,Normal,130/85,68,8000,None\\n131,Female,38,Accountant,7.1,8,60,4,Normal,115/75,68,7000,None\\n132,Male,38,Lawyer,7.3,8,60,5,Normal,130/85,68,8000,None\\n133,Male,38,Lawyer,7.3,8,60,5,Normal,130/85,68,8000,None\\n134,Female,38,Accountant,7.1,8,60,4,Normal,115/75,68,7000,None\\n135,Male,38,Lawyer,7.3,8,60,5,Normal,130/85,68,8000,None\\n136,Male,38,Lawyer,7.3,8,60,5,Normal,130/85,68,8000,None\\n137,Female,38,Accountant,7.1,8,60,4,Normal,115/75,68,7000,None\\n138,Male,38,Lawyer,7.1,8,60,5,Normal,130/85,68,8000,None\\n139,Female,38,Accountant,7.1,8,60,4,Normal,115/75,68,7000,None\\n140,Male,38,Lawyer,7.1,8,60,5,Normal,130/85,68,8000,None\\n141,Female,38,Accountant,7.1,8,60,4,Normal,115/75,68,7000,None\\n142,Male,38,Lawyer,7.1,8,60,5,Normal,130/85,68,8000,None\\n143,Female,38,Accountant,7.1,8,60,4,Normal,115/75,68,7000,None\\n144,Female,38,Accountant,7.1,8,60,4,Normal,115/75,68,7000,None\\n145,Male,38,Lawyer,7.1,8,60,5,Normal,130/85,68,8000,Sleep Apnea\\n146,Female,38,Lawyer,7.4,7,60,5,Obese,135/88,84,3300,Sleep Apnea\\n147,Male,39,Lawyer,7.2,8,60,5,Normal,130/85,68,8000,Insomnia\\n148,Male,39,Engineer,6.5,5,40,7,Overweight,132/87,80,4000,Insomnia\\n149,Female,39,Lawyer,6.9,7,50,6,Normal Weight,128/85,75,5500,None\\n150,Female,39,Accountant,8,9,80,3,Normal Weight,115/78,67,7500,None\\n151,Female,39,Accountant,8,9,80,3,Normal Weight,115/78,67,7500,None\\n152,Male,39,Lawyer,7.2,8,60,5,Normal,130/85,68,8000,None\\n153,Male,39,Lawyer,7.2,8,60,5,Normal,130/85,68,8000,None\\n154,Male,39,Lawyer,7.2,8,60,5,Normal,130/85,68,8000,None\\n155,Male,39,Lawyer,7.2,8,60,5,Normal,130/85,68,8000,None\\n156,Male,39,Lawyer,7.2,8,60,5,Normal,130/85,68,8000,None\\n157,Male,39,Lawyer,7.2,8,60,5,Normal,130/85,68,8000,None\\n158,Male,39,Lawyer,7.2,8,60,5,Normal,130/85,68,8000,None\\n159,Male,39,Lawyer,7.2,8,60,5,Normal,130/85,68,8000,None\\n160,Male,39,Lawyer,7.2,8,60,5,Normal,130/85,68,8000,None\\n161,Male,39,Lawyer,7.2,8,60,5,Normal,130/85,68,8000,None\\n162,Female,40,Accountant,7.2,8,55,6,Normal Weight,119/77,73,7300,None\\n163,Female,40,Accountant,7.2,8,55,6,Normal Weight,119/77,73,7300,None\\n164,Male,40,Lawyer,7.9,8,90,5,Normal,130/85,68,8000,None\\n165,Male,40,Lawyer,7.9,8,90,5,Normal,130/85,68,8000,None\\n166,Male,41,Lawyer,7.6,8,90,5,Normal,130/85,70,8000,Insomnia\\n167,Male,41,Engineer,7.3,8,70,6,Normal Weight,121/79,72,6200,None\\n168,Male,41,Lawyer,7.1,7,55,6,Overweight,125/82,72,6000,None\\n169,Male,41,Lawyer,7.1,7,55,6,Overweight,125/82,72,6000,None\\n170,Male,41,Lawyer,7.7,8,90,5,Normal,130/85,70,8000,None\\n171,Male,41,Lawyer,7.7,8,90,5,Normal,130/85,70,8000,None\\n172,Male,41,Lawyer,7.7,8,90,5,Normal,130/85,70,8000,None\\n173,Male,41,Lawyer,7.7,8,90,5,Normal,130/85,70,8000,None\\n174,Male,41,Lawyer,7.7,8,90,5,Normal,130/85,70,8000,None\\n175,Male,41,Lawyer,7.6,8,90,5,Normal,130/85,70,8000,None\\n176,Male,41,Lawyer,7.6,8,90,5,Normal,130/85,70,8000,None\\n177,Male,41,Lawyer,7.6,8,90,5,Normal,130/85,70,8000,None\\n178,Male,42,Salesperson,6.5,6,45,7,Overweight,130/85,72,6000,Insomnia\\n179,Male,42,Lawyer,7.8,8,90,5,Normal,130/85,70,8000,None\\n180,Male,42,Lawyer,7.8,8,90,5,Normal,130/85,70,8000,None\\n181,Male,42,Lawyer,7.8,8,90,5,Normal,130/85,70,8000,None\\n182,Male,42,Lawyer,7.8,8,90,5,Normal,130/85,70,8000,None\\n183,Male,42,Lawyer,7.8,8,90,5,Normal,130/85,70,8000,None\\n184,Male,42,Lawyer,7.8,8,90,5,Normal,130/85,70,8000,None\\n185,Female,42,Teacher,6.8,6,45,7,Overweight,130/85,78,5000,Sleep Apnea\\n186,Female,42,Teacher,6.8,6,45,7,Overweight,130/85,78,5000,Sleep Apnea\\n187,Female,43,Teacher,6.7,7,45,4,Overweight,135/90,65,6000,Insomnia\\n188,Male,43,Salesperson,6.3,6,45,7,Overweight,130/85,72,6000,Insomnia\\n189,Female,43,Teacher,6.7,7,45,4,Overweight,135/90,65,6000,Insomnia\\n190,Male,43,Salesperson,6.5,6,45,7,Overweight,130/85,72,6000,Insomnia\\n191,Female,43,Teacher,6.7,7,45,4,Overweight,135/90,65,6000,Insomnia\\n192,Male,43,Salesperson,6.4,6,45,7,Overweight,130/85,72,6000,Insomnia\\n193,Male,43,Salesperson,6.5,6,45,7,Overweight,130/85,72,6000,Insomnia\\n194,Male,43,Salesperson,6.5,6,45,7,Overweight,130/85,72,6000,Insomnia\\n195,Male,43,Salesperson,6.5,6,45,7,Overweight,130/85,72,6000,Insomnia\\n196,Male,43,Salesperson,6.5,6,45,7,Overweight,130/85,72,6000,Insomnia\\n197,Male,43,Salesperson,6.5,6,45,7,Overweight,130/85,72,6000,Insomnia\\n198,Male,43,Salesperson,6.5,6,45,7,Overweight,130/85,72,6000,Insomnia\\n199,Male,43,Salesperson,6.5,6,45,7,Overweight,130/85,72,6000,Insomnia\\n200,Male,43,Salesperson,6.5,6,45,7,Overweight,130/85,72,6000,Insomnia\\n201,Male,43,Salesperson,6.5,6,45,7,Overweight,130/85,72,6000,Insomnia\\n202,Male,43,Engineer,7.8,8,90,5,Normal,130/85,70,8000,Insomnia\\n203,Male,43,Engineer,7.8,8,90,5,Normal,130/85,70,8000,Insomnia\\n204,Male,43,Engineer,6.9,6,47,7,Normal Weight,117/76,69,6800,None\\n205,Male,43,Engineer,7.6,8,75,4,Overweight,122/80,68,6800,None\\n206,Male,43,Engineer,7.7,8,90,5,Normal,130/85,70,8000,None\\n207,Male,43,Engineer,7.7,8,90,5,Normal,130/85,70,8000,None\\n208,Male,43,Engineer,7.7,8,90,5,Normal,130/85,70,8000,None\\n209,Male,43,Engineer,7.7,8,90,5,Normal,130/85,70,8000,None\\n210,Male,43,Engineer,7.8,8,90,5,Normal,130/85,70,8000,None\\n211,Male,43,Engineer,7.7,8,90,5,Normal,130/85,70,8000,None\\n212,Male,43,Engineer,7.8,8,90,5,Normal,130/85,70,8000,None\\n213,Male,43,Engineer,7.8,8,90,5,Normal,130/85,70,8000,None\\n214,Male,43,Engineer,7.8,8,90,5,Normal,130/85,70,8000,None\\n215,Male,43,Engineer,7.8,8,90,5,Normal,130/85,70,8000,None\\n216,Male,43,Engineer,7.8,8,90,5,Normal,130/85,70,8000,None\\n217,Male,43,Engineer,7.8,8,90,5,Normal,130/85,70,8000,None\\n218,Male,43,Engineer,7.8,8,90,5,Normal,130/85,70,8000,None\\n219,Male,43,Engineer,7.8,8,90,5,Normal,130/85,70,8000,Sleep Apnea\\n220,Male,43,Salesperson,6.5,6,45,7,Overweight,130/85,72,6000,Sleep Apnea\\n221,Female,44,Teacher,6.6,7,45,4,Overweight,135/90,65,6000,Insomnia\\n222,Male,44,Salesperson,6.4,6,45,7,Overweight,130/85,72,6000,Insomnia\\n223,Male,44,Salesperson,6.3,6,45,7,Overweight,130/85,72,6000,Insomnia\\n224,Male,44,Salesperson,6.4,6,45,7,Overweight,130/85,72,6000,Insomnia\\n225,Female,44,Teacher,6.6,7,45,4,Overweight,135/90,65,6000,Insomnia\\n226,Male,44,Salesperson,6.3,6,45,7,Overweight,130/85,72,6000,Insomnia\\n227,Female,44,Teacher,6.6,7,45,4,Overweight,135/90,65,6000,Insomnia\\n228,Male,44,Salesperson,6.3,6,45,7,Overweight,130/85,72,6000,Insomnia\\n229,Female,44,Teacher,6.6,7,45,4,Overweight,135/90,65,6000,Insomnia\\n230,Male,44,Salesperson,6.3,6,45,7,Overweight,130/85,72,6000,Insomnia\\n231,Female,44,Teacher,6.6,7,45,4,Overweight,135/90,65,6000,Insomnia\\n232,Male,44,Salesperson,6.3,6,45,7,Overweight,130/85,72,6000,Insomnia\\n233,Female,44,Teacher,6.6,7,45,4,Overweight,135/90,65,6000,Insomnia\\n234,Male,44,Salesperson,6.3,6,45,7,Overweight,130/85,72,6000,Insomnia\\n235,Female,44,Teacher,6.6,7,45,4,Overweight,135/90,65,6000,Insomnia\\n236,Male,44,Salesperson,6.3,6,45,7,Overweight,130/85,72,6000,Insomnia\\n237,Male,44,Salesperson,6.4,6,45,7,Overweight,130/85,72,6000,Insomnia\\n238,Female,44,Teacher,6.5,7,45,4,Overweight,135/90,65,6000,Insomnia\\n239,Male,44,Salesperson,6.3,6,45,7,Overweight,130/85,72,6000,Insomnia\\n240,Male,44,Salesperson,6.4,6,45,7,Overweight,130/85,72,6000,Insomnia\\n241,Female,44,Teacher,6.5,7,45,4,Overweight,135/90,65,6000,Insomnia\\n242,Male,44,Salesperson,6.3,6,45,7,Overweight,130/85,72,6000,Insomnia\\n243,Male,44,Salesperson,6.4,6,45,7,Overweight,130/85,72,6000,Insomnia\\n244,Female,44,Teacher,6.5,7,45,4,Overweight,135/90,65,6000,Insomnia\\n245,Male,44,Salesperson,6.3,6,45,7,Overweight,130/85,72,6000,Insomnia\\n246,Female,44,Teacher,6.5,7,45,4,Overweight,135/90,65,6000,Insomnia\\n247,Male,44,Salesperson,6.3,6,45,7,Overweight,130/85,72,6000,Insomnia\\n248,Male,44,Engineer,6.8,7,45,7,Overweight,130/85,78,5000,Insomnia\\n249,Male,44,Salesperson,6.4,6,45,7,Overweight,130/85,72,6000,None\\n250,Male,44,Salesperson,6.5,6,45,7,Overweight,130/85,72,6000,None\\n251,Female,45,Teacher,6.8,7,30,6,Overweight,135/90,65,6000,Insomnia\\n252,Female,45,Teacher,6.8,7,30,6,Overweight,135/90,65,6000,Insomnia\\n253,Female,45,Teacher,6.5,7,45,4,Overweight,135/90,65,6000,Insomnia\\n254,Female,45,Teacher,6.5,7,45,4,Overweight,135/90,65,6000,Insomnia\\n255,Female,45,Teacher,6.5,7,45,4,Overweight,135/90,65,6000,Insomnia\\n256,Female,45,Teacher,6.5,7,45,4,Overweight,135/90,65,6000,Insomnia\\n257,Female,45,Teacher,6.6,7,45,4,Overweight,135/90,65,6000,Insomnia\\n258,Female,45,Teacher,6.6,7,45,4,Overweight,135/90,65,6000,Insomnia\\n259,Female,45,Teacher,6.6,7,45,4,Overweight,135/90,65,6000,Insomnia\\n260,Female,45,Teacher,6.6,7,45,4,Overweight,135/90,65,6000,Insomnia\\n261,Female,45,Teacher,6.6,7,45,4,Overweight,135/90,65,6000,Insomnia\\n262,Female,45,Teacher,6.6,7,45,4,Overweight,135/90,65,6000,None\\n263,Female,45,Teacher,6.6,7,45,4,Overweight,135/90,65,6000,None\\n264,Female,45,Manager,6.9,7,55,5,Overweight,125/82,75,5500,None\\n265,Male,48,Doctor,7.3,7,65,5,Obese,142/92,83,3500,Insomnia\\n266,Female,48,Nurse,5.9,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n267,Male,48,Doctor,7.3,7,65,5,Obese,142/92,83,3500,Insomnia\\n268,Female,49,Nurse,6.2,6,90,8,Overweight,140/95,75,10000,None\\n269,Female,49,Nurse,6,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n270,Female,49,Nurse,6.1,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n271,Female,49,Nurse,6.1,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n272,Female,49,Nurse,6.1,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n273,Female,49,Nurse,6.1,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n274,Female,49,Nurse,6.2,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n275,Female,49,Nurse,6.2,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n276,Female,49,Nurse,6.2,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n277,Male,49,Doctor,8.1,9,85,3,Obese,139/91,86,3700,Sleep Apnea\\n278,Male,49,Doctor,8.1,9,85,3,Obese,139/91,86,3700,Sleep Apnea\\n279,Female,50,Nurse,6.1,6,90,8,Overweight,140/95,75,10000,Insomnia\\n280,Female,50,Engineer,8.3,9,30,3,Normal,125/80,65,5000,None\\n281,Female,50,Nurse,6,6,90,8,Overweight,140/95,75,10000,None\\n282,Female,50,Nurse,6.1,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n283,Female,50,Nurse,6,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n284,Female,50,Nurse,6,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n285,Female,50,Nurse,6,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n286,Female,50,Nurse,6,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n287,Female,50,Nurse,6,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n288,Female,50,Nurse,6,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n289,Female,50,Nurse,6,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n290,Female,50,Nurse,6.1,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n291,Female,50,Nurse,6,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n292,Female,50,Nurse,6.1,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n293,Female,50,Nurse,6.1,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n294,Female,50,Nurse,6,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n295,Female,50,Nurse,6.1,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n296,Female,50,Nurse,6,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n297,Female,50,Nurse,6.1,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n298,Female,50,Nurse,6.1,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n299,Female,51,Engineer,8.5,9,30,3,Normal,125/80,65,5000,None\\n300,Female,51,Engineer,8.5,9,30,3,Normal,125/80,65,5000,None\\n301,Female,51,Engineer,8.5,9,30,3,Normal,125/80,65,5000,None\\n302,Female,51,Engineer,8.5,9,30,3,Normal,125/80,65,5000,None\\n303,Female,51,Nurse,7.1,7,55,6,Normal Weight,125/82,72,6000,None\\n304,Female,51,Nurse,6,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n305,Female,51,Nurse,6.1,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n306,Female,51,Nurse,6.1,6,90,8,Overweight,140/95,75,10000,Sleep Apnea\\n307,Female,52,Accountant,6.5,7,45,7,Overweight,130/85,72,6000,Insomnia\\n308,Female,52,Accountant,6.5,7,45,7,Overweight,130/85,72,6000,Insomnia\\n309,Female,52,Accountant,6.6,7,45,7,Overweight,130/85,72,6000,Insomnia\\n310,Female,52,Accountant,6.6,7,45,7,Overweight,130/85,72,6000,Insomnia\\n311,Female,52,Accountant,6.6,7,45,7,Overweight,130/85,72,6000,Insomnia\\n312,Female,52,Accountant,6.6,7,45,7,Overweight,130/85,72,6000,Insomnia\\n313,Female,52,Engineer,8.4,9,30,3,Normal,125/80,65,5000,None\\n314,Female,52,Engineer,8.4,9,30,3,Normal,125/80,65,5000,None\\n315,Female,52,Engineer,8.4,9,30,3,Normal,125/80,65,5000,None\\n316,Female,53,Engineer,8.3,9,30,3,Normal,125/80,65,5000,Insomnia\\n317,Female,53,Engineer,8.5,9,30,3,Normal,125/80,65,5000,None\\n318,Female,53,Engineer,8.5,9,30,3,Normal,125/80,65,5000,None\\n319,Female,53,Engineer,8.4,9,30,3,Normal,125/80,65,5000,None\\n320,Female,53,Engineer,8.4,9,30,3,Normal,125/80,65,5000,None\\n321,Female,53,Engineer,8.5,9,30,3,Normal,125/80,65,5000,None\\n322,Female,53,Engineer,8.4,9,30,3,Normal,125/80,65,5000,None\\n323,Female,53,Engineer,8.4,9,30,3,Normal,125/80,65,5000,None\\n324,Female,53,Engineer,8.5,9,30,3,Normal,125/80,65,5000,None\\n325,Female,53,Engineer,8.3,9,30,3,Normal,125/80,65,5000,None\\n326,Female,53,Engineer,8.5,9,30,3,Normal,125/80,65,5000,None\\n327,Female,53,Engineer,8.3,9,30,3,Normal,125/80,65,5000,None\\n328,Female,53,Engineer,8.5,9,30,3,Normal,125/80,65,5000,None\\n329,Female,53,Engineer,8.3,9,30,3,Normal,125/80,65,5000,None\\n330,Female,53,Engineer,8.5,9,30,3,Normal,125/80,65,5000,None\\n331,Female,53,Engineer,8.5,9,30,3,Normal,125/80,65,5000,None\\n332,Female,53,Engineer,8.4,9,30,3,Normal,125/80,65,5000,None\\n333,Female,54,Engineer,8.4,9,30,3,Normal,125/80,65,5000,None\\n334,Female,54,Engineer,8.4,9,30,3,Normal,125/80,65,5000,None\\n335,Female,54,Engineer,8.4,9,30,3,Normal,125/80,65,5000,None\\n336,Female,54,Engineer,8.4,9,30,3,Normal,125/80,65,5000,None\\n337,Female,54,Engineer,8.4,9,30,3,Normal,125/80,65,5000,None\\n338,Female,54,Engineer,8.4,9,30,3,Normal,125/80,65,5000,None\\n339,Female,54,Engineer,8.5,9,30,3,Normal,125/80,65,5000,None\\n340,Female,55,Nurse,8.1,9,75,4,Overweight,140/95,72,5000,Sleep Apnea\\n341,Female,55,Nurse,8.1,9,75,4,Overweight,140/95,72,5000,Sleep Apnea\\n342,Female,56,Doctor,8.2,9,90,3,Normal Weight,118/75,65,10000,None\\n343,Female,56,Doctor,8.2,9,90,3,Normal Weight,118/75,65,10000,None\\n344,Female,57,Nurse,8.1,9,75,3,Overweight,140/95,68,7000,None\\n345,Female,57,Nurse,8.2,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n346,Female,57,Nurse,8.2,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n347,Female,57,Nurse,8.2,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n348,Female,57,Nurse,8.2,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n349,Female,57,Nurse,8.2,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n350,Female,57,Nurse,8.1,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n351,Female,57,Nurse,8.1,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n352,Female,57,Nurse,8.1,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n353,Female,58,Nurse,8,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n354,Female,58,Nurse,8,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n355,Female,58,Nurse,8,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n356,Female,58,Nurse,8,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n357,Female,58,Nurse,8,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n358,Female,58,Nurse,8,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n359,Female,59,Nurse,8,9,75,3,Overweight,140/95,68,7000,None\\n360,Female,59,Nurse,8.1,9,75,3,Overweight,140/95,68,7000,None\\n361,Female,59,Nurse,8.2,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n362,Female,59,Nurse,8.2,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n363,Female,59,Nurse,8.2,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n364,Female,59,Nurse,8.2,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n365,Female,59,Nurse,8,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n366,Female,59,Nurse,8,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n367,Female,59,Nurse,8.1,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n368,Female,59,Nurse,8,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n369,Female,59,Nurse,8.1,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n370,Female,59,Nurse,8.1,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n371,Female,59,Nurse,8,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n372,Female,59,Nurse,8.1,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n373,Female,59,Nurse,8.1,9,75,3,Overweight,140/95,68,7000,Sleep Apnea\\n374,Female,59,Nurse,8.1,9,75,3,Overweight,140/95,68,7000,Sleep Apnea', metadata={'source': 'C:/Users/DELL/Desktop/Data Science/Datasets/Sleep_health_and_lifestyle_dataset.csv'})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"C:/Users/DELL/Desktop/Data Science/Datasets/Sleep_health_and_lifestyle_dataset.csv\")\n",
    "documents = loader.load()\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "51f4bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Velocity Corporate Training Center, Pune\\nTopic: Python Loops\\nWrite   a   Python  Program  to   print   below   Patterns\\nusing For and\\nWhile Loop:   \\n1.\\n*     \\n*   *     \\n*   *   *     \\n*   *   *   *     \\n*   *   *   *   *     \\n2.\\n *     \\n *   *     \\n *   *   *     \\n *   *   *   *     \\n*   *   *   *   *     \\n3.\\n \\n *     \\n *   *     \\n *   *   *     \\n *   *   *   *     \\n*   *   *   *   *     \\n \\n4.\\n1     \\n1   2     \\n1   2   3     \\n1   2   3   4     \\n1   2   3   4   5     \\n5.\\n1     \\n2   3     \\n4   5   6     \\n7   8   9   10     \\n11   12   13   14   15     \\n \\n6.\\nA                [Use   ASCII   Values]   \\nB   B     \\nC   C   C     \\nD   D   D   D     \\nE   E   E   E   E' metadata={'source': 'C:/Users/DELL/Desktop/Data Science/Assignments/Assignment-3(Pattern-Loops).pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"C:/Users/DELL/Desktop/Data Science/Assignments/Assignment-3(Pattern-Loops).pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786cbb12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a949c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "791f37d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.16.0-py3-none-any.whl (10.0 MB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.23.2-py3-none-any.whl (461 kB)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Collecting sniffio>=1.3.0\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: idna in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Collecting exceptiongroup\n",
      "  Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Installing collected packages: sniffio, outcome, exceptiongroup, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed exceptiongroup-1.2.0 outcome-1.3.0.post0 selenium-4.16.0 sniffio-1.3.0 trio-0.23.2 trio-websocket-0.11.1 wsproto-1.2.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "googletrans 3.0.0 requires httpx==0.13.3, but you have httpx 0.25.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f716a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91abe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import SeleniumURLLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://www.youtube.com/watch?v=TFa539R09EQ&t=139s\",\n",
    "    \"https://www.youtube.com/watch?v=6Zv6A_9urh4&t=112s\"\n",
    "]\n",
    "\n",
    "loader = SeleniumURLLoader(urls=urls)            #SeleniumURLLoader (URL)\n",
    "data = loader.load()\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef264c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43442fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GoogleDriveLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae258c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GoogleDriveLoader(\n",
    "    folder_id=\"your_folder_id\",\n",
    "    recursive=False  # Optional: Fetch files from subfolders recursively. Defaults to False.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4fa14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
